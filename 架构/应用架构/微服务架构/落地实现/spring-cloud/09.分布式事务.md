##  事务的基础知识

* 事务的ACID
* 事务的隔离级别
* spring中事务的传播机制



## 分布式事务相关的理论知识

### XA规范与2PC协议

#### XA规范

X/OPOEN组织对分布式事务在理论上提出了解决方案，其解决方案中包含以下几个角色：

* AP（Application，应用程序）：就是我们自己的系统
* TM（Transaction Manager，事务管理者）：一个第三方的组件
* RM（Resource Manager，资源管理者）：其实就是一个一个的数据库
* CRM（Communication Resource Manager，通信资源管理器）：一般由消息中间件来担任这个角色



​	**全局事务的概念**

​	一个事务横跨多个库，这个事务就叫做全局事务。

​	TM和RM之间的交互的通信接口规范，就叫做XA规范。



#### 2PC（两阶段提交的协议）

XA只是一个规范，但是没有落地。2PC是基于XA规范搞得一套分布式事务理论，亦可以叫做规范或者协议。关于2PC协议有如下理解：

2PC顾名思义，通过两个阶段确保全局事务的实现：

1. prepare阶段，TM让每一个RM都把SQL执行一下，但是不提交，也就是还能够进行数据的回滚
2. commit阶段
   * 如果prepare阶段，RM中所有的SQL都能够正常执行，那么TM会让所有的RM把事务提交上去
   * 如果prepare阶段，存在任意一个RM中的SQL执行失败，那么TM会让所有的RM把事务回滚



#### 2PC存在的缺陷

**同步阻塞**

prepare阶段，RM可能会锁定一些资源；commit阶段，RM才能够把资源释放掉。这种情况下，会导致存在一定的资源浪费，第三方来访问被锁定的资源的时候，会存在一定的时间窗，没有任何人使用这个资源，但是第三方任然无法获取到这个资源。



**单点的TM**

单点故障，会导致系统不可用，数据不一致，资源不可用等一些列问题



**事务状态丢失**

为了避免单点的TM导致的可用性问题，可以把TM做成双击热备，当一个TM宕机的时候可以选举出另外的一个TM。先假设有如下情况，有TM1和TM2两个TM，并且有RM1、RM2、RM3三个RM。prepare阶段已经执行结束，到了commit阶段，TM1给RM1发送完commit之后，TM1和RM1同时宕机，此时会选举出TM2作为TM，可是此时TM并不知道当前事务处于什么状态，因为RM1也挂了，这个就叫做事务的状态丢失。



**脑裂问题**

commit阶段，有某个RM由于网络问题导致无法执行commit，会导致数据不一致的问题。





### 3PC分布式事务方案的理论知识

顾名思义，3PC分为3个阶段：

1. cancommit：确保网络等基础环境是正常的
2. precommit：cancommit没问题的话，执行这个阶段。相当于2PC的第一个阶段；cancommit有问题，发送abort消息
3. docommit：precommit没问题的话，执行这个阶段。相当于2PC的第二个阶段；precommit有问题，发送abort消息

另外，3PC增加了**超时机制**：

如果一个库，在执行完了precommit之后，经过了一段时间没接收到docommit消息，自己会自动执行commit操作。

#### 过程和原理图

<img src="9.%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/07_3PC%E7%9A%84%E8%BF%87%E7%A8%8B%E5%92%8C%E5%8E%9F%E7%90%86-0819225.png" alt="07_3PC的过程和原理"  />

3PC只是轻度缓解了2PC的问题，但是依然不能完美的解决分布式事务中存在的问题。



> 由此可见，复杂的系统会引入更多的隐患，不能将这些隐患置之不理，当这些隐患在真实场景中引发了一些问题的时候，我们所使用的技术底座最好要有一些机制能够自动的将错误进行恢复，但是有些由于复杂架构所带来的隐患可能是无论如何都无法避免的，这个时候就要综合考虑是否真的要引入这个架构了。
>
> 放在微服务架构上来说，微服务架构带来了很多的好处，解决了很多的问题，但是同时微服务架构也是比单体架构更加复杂的架构，复杂的架构势必会带来一些问题，比如说：分布式事务。因此，在选用架构的时候，不但要考虑到该架构在整体上带来了多大的好处，也要考虑其带来的隐患以及解决这些隐患所要付出的代价。另外，还要考虑当无法很好的解决这些隐患的时候，其产生的问题会给我们带来多大的麻烦。当结合正面和反面的反复论证之后，得出一个综合性的结论，再去决定是否要引入复杂的架构。
>
> 不单单是架构，在引入某些技术框架以及中间件的时候，也应该如此。



### CAP和BASE的基础知识

#### CAP

**Consistency，一致性**

先说说C，就是一致性吧，这个其实很好理解，就是说一个分布式系统中，一旦你做了一个数据的修改，那么这个操作成功的时候，就必须是分布式系统的各个节点都是一样的， 

能说，客户端发起一个数据修改的请求，然后服务器告诉他成功了，结果去查的时候，从某个节点上查询数据，发现这个数据不对啊，这样的话就成了数据不一致了，就是分布式系统的各个节点上的数据是不一样的，就是不一致。

这个所谓一致性还分成几种：

* **强一致性**，就是说上面讲的那种就是强一致性；**弱一致性**呢，就是你更新个数据，鬼知道能不能让各个节点都更新成功；

* **最终一致性**，就是可能更新过后，一段时间内，数据不一致，最后过了一段时间成功了。

最终一致性，应该是分布式系统中**非常常见**的这么一个东西，redis主从同步，你可以做成主从异步同步的，主节点同步数据到从节点上去的时候，异步，最终一致性的体现。

你的一个客户端往redis主节点里面写入了一条数据，在一段时间内，你客户端如果从redis从节点去查询数据，此时可能是查不到的，但是redis主从机制给你保证的是，过了一段时间之后，你再查，一定是可以从redis从节点里查到的。



**Availability，可用性**

这个A，就是可用性，其实也很好理解，就是你的分布式系统必须是可用的啊，说句不好听的，要是一会儿访问你是成功，一会儿访问你失败，那失败的时候就是不可用，有不可用的情况存在，就导致可用性降低了

什么叫做可用？客户端往分布式系统的各个节点发送请求，都是可以获取到响应的，要不是可以写入成功，要不是可以查询成功；什么叫做不可用呢？客户端往分布式系统中的各个节点发送请求的时候，获取不到响应结果，这个时候，系统就是不可用了，写入失败，人家不让你写入，不接受你的请求 。

可用性分成好多级别，比如99%，99.9%，99.99%，99.999%

99%，一年中只能有80小时左右是可以允许访问失败的

99.9%，一年中大概有8小时左右是可以访问失败

99.99%，一年中有大概不到1小时是可以访问失败的

99.999%，一年中有大概不到5分钟是可以访问失败的

99.9999%，一年中只能有大概不到1分钟可以访问失败

那一般来说，就我个人观察，很多行业大部分的系统，其实99%可用性都没到，或者可能大概就在99%是一个很正常的水平，每年总得故障几次。能做到99.9%的系统就算是比较牛的了，也算很不错了，毕竟一年内就几个小时不可用。



**Partition Tolerence，分区容忍性**

分区，partition，network partition，网络分区 => 分布式系统之间的网络环境出了故障，分布式系统的各个节点之间现在已经无法进行通信了

分区容忍性，你的分布式系统可以容忍网络分区的故障，出现上面说的那种网络分区的故障之后，分布式系统的各个节点之间无法进行通信，无所谓，整套分布式系统各个节点，各自为战，该干嘛干嘛，只不过互相之间无法通信而已 

分布式系统还是在运转着，你分别给各个节点发送请求，人家还是可以给你一些响应结果的，这个就是实现了分区容忍性

这玩意儿搞的稀奇古怪的，啥东西啊，其实说白了，就是一个分布式的系统，如果遇到了网络分区的故障，也就是说，分布式系统互相之间无法联通了，这个时候咋整呢，有点儿恶心啊，这里要求的是，遇到网络分区故障，也类似于传说中的脑裂吧，然后系统还是可以正常对外提供服务的

如果不具备分区容忍性，那会怎么样呢？那就是说一旦网络故障，整套系统崩溃，你哪怕给各个节点发送消息，全部失败，清一色失败，整套系统甚至会宕机，不再运转了



#### CAP不可能三者兼得

要么CP，要么AP。为什么呢？



##### CP

假设，出现了网络分区的故障，但是因为有P，所以分布式系统继续运转，但是此时分布式系统的节点之间无法进行通信，也就无法同步数据了

此时客户端要来查询数据，也就是那个key1的数据了，此时系统实际上是处于一个不一致的状态，因为各个节点之间的数据是不一样的，如果客户端来查询key1这条数据，你要是要保证CP的话，就得返回一个特殊的结果（异常）给客户端

任何一个节点此时不接收任何查询的请求，返回一个异常（系统当前处于不一致的状态，无法查询），这样的话呢，客户端是看不到不一致的数据的

此时对客户端而言，要么查到的是一致性的数据，要么如果数据不一致什么都查不到，不让你看到不一致的数据，这就保证了CAP里的C，一致性，分布式系统本身处于不一致的时候，让你看不到不一致的数据，就保证了一致性，保证了CP

但是此时的话，就牺牲掉了A，可用性，因为此时不让你看到不一致的数据，所以你发送请求过来是返回异常的，请求失败了，此时分布式系统就暂时处于不可用的状态下，也就是保证了CP，就没有了A

弄个分布式系统给大家演示一下，就俩节点，假设现在发生了网络分区故障，好了，那么P起码要保证吧，就是网络分区的时候，系统还是要正常可以运行的，所以P先保证了，对吧，然后呢，因为网络分区，导致俩节点互相不能通信了

现在呢，你写入一条数据到其中一个节点，好了，结果这个节点没法同步数据到其他的节点上去啊，咋整呢，尴尬啊尴尬，俩节点上数据不一致了

所以这个时候，如果你要满足C，也就是一致性，你觉得应该怎么办，你要是继续让所有人访问两个节点，那数据100%不一致，一会儿数据这样，一会儿数据那样，这个时候，你就只能牺牲掉A了

也就是说，在这种情况下，你的系统直接对外不再提供服务，人家查询直接返回异常，不让查到不一致的数据，不就可以保证一致性了，呵呵，但是你就牺牲了可用性了，因为这个时候你的系统是不可用的

经典的就是一些分布式存储，比如说zookeeper、mongodb、hbase等等，跟他们都是CP的，也就是说数据100%一致，但是有可能有些时候你请求是失败的，不让你请求到不一致的数据，这就是CP

如果要保证CP的话，C，保证说你在任何情况下写入一条数据，接着从任何一个节点去查都可以看到一致的数据，不可能让你一会儿看到旧数据，一会儿看到的是新数据，这样就保证了一致性

有些特殊的情况下，确实数据就是没法同步，没法一致性，此时可能就得牺牲A了，可能短暂的情况下，你发送请求过去人家返回异常给你，此时就是短暂不可用的，让你过段时间在重试查询



##### AP

如果网络故障，数据没同步，数据处于不一致的状态下，要保证A，可用性，你两个节点都要允许任何客户端来查询，都可以查到，这样的话呢，整个系统就处于可用的状态下，但是此时就牺牲掉了C

一会儿可以查到key1的数据，一会儿从另外一个节点去查又查不到了，这就是对客户端而言，看到了不一致的数据

在各种分布式系统里面，CAP不可能同时兼得，指的主要是什么呢，就是发生网络故障的时候，可能一些数据没有同步一致性，此时要么就是CP，要么就是AP

那如果要保证AP呢，也就是可用性必须保证，人家过来查必须给人查，那就牺牲掉一致性咯，随便查，要怎么查怎么查，但是查到的数据不一致，那我不管了，反正就这么回事儿了，哈哈哈。。。起码我可用性保证了，一致性就没了

对于12306、电商系统，这种业务类系统，一般都是AP，也就是说，你可能看到的商品库存或者火车票的库存，是错的，有可能是旧的啊，那么数据很可能看到的都是不一致的，但是呢，你买东西或者买票的时候，一定会检查库存，就可以了

但是保证了可用性就ok，任何时候都要响应结果，不能动不动就失败

12306买票，AP，C其实是没保证的。很多人同时在订票，每次订票之后这个车票的库存就会扣减，但是车票库存扣减之后，可能不能及时的被你的12306网站展示出来，可能你查询的车票的库存，是从另外一个库里去查的，最新的库存数据还没同步过来，此时数据是不一致的 

所以你看到的是不一致的数据，但是AP，可用性是保证的，时时刻刻都让你可以看到数据，可以买票，可以查询，但是呢可能你看到的车票还剩5张，但是你发起订票的时候，人家一检查最新的库存，判断已经是0张了，就不让你买了呗



#### Base理论

所谓的BASE，Basicly Available、Soft State、Eventual Consistency，也就是基本可用、软状态、最终一致性

BASE希望的是，CAP里面**基本**都可以同时实现，但是不要求同时全部100%完美的实现，CAP三者同时基本实现，BASE，基本可用、最终一致性

此时要保证基本可用性，应该怎么办呢？两个节点都可以查询的，但是这个时候你会发现说有的节点可以返回数据，有的节点无法返回数据，会看到不一致的状态，这个不一致的状态，就是指的是BASE中的S，soft state，软状态

基本可用，降级，正常情况下，是查询可以负载均衡到各个节点去查的，也就是可以多节点抗高并发查询，但是此时如果你要降级的话，可以降级为，所有客户端强制查询主节点，这样看到的数据暂时而言都是一样的，都是从主节点去查

但是因为客户端访问量太大了，同时用一个主节点来支撑很坑，扛不住，怎么办呢，主节点做限流降级，也就是说如果流量太大了，直接返回一个空，让你稍后再来查询

如果你这样子来降级了，保证的就是所谓的基本可用，降级的措施在里面了，跟正常的可用是不一样的，比正常的可用要差一些，但是还是基本可以用的

最终一致性，一旦故障或者延迟解决了，数据过了一段时间最终一定是可以同步到其他节点的，数据最终一定是可以处于一致性的

这个基本可用的意思，就是说可以适当进行降级，比如说某些系统是可以进行降级的，在故障的时候，直接引导到降级的一些功能里去，举个例子吧，本来商品详情页可以是个极度华丽的页面，但是如果降级的话，那么就变成一个比较简陋的页面，里面包含少量数据

软状态意思就是说，可以存在中间的数据状态，就是比如多个节点在同步数据，在一段时间内，可能每个节点数据不一致，正在同步过程中，这个就是软状态 

最终一致性，就是说，虽然存在软状态，但是最终还是会变成一致的



所以说，CAP和BASE是俩理论，是俩基础理论，你在设计分布式系统的话，可以用CAP中的CP或者AP，也可以采用BASE理论，有一些不一样，也有一些关系





## 分布式事务常见的解决方案

> 注意：在微服务的架构规范当中，一个系统是不允许访问多个不同的数据库的，每个系统只允许访问自己的数据库，如果想访问其他的数据库，需要调用其他系统所提供的服务，绝对不允许交叉访问。否则，100多个服务，都搞乱套了。



### 两阶段提交方案

两阶段提交现在一般不用了，因为微服务的规范规定了不允许一个系统访问多个数据库。因此，该方案在微服务当中没有什么用武之地。



### TCC方案

* try 

* confirm 

* cancel

需要手写一系列的代码。这种方案虽然在微服务当中能够作为一种分布式事务的解决方案，但是并不常用。除非是非常核心的功能，这种功能一般会要求强事务。比如跟钱相关的。TCC是很复杂的，这种代码是很不好维护的。

![04_TCC方案](9.%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/04_TCC%E6%96%B9%E6%A1%88.png)



### 本地消息表方案

国外的ebay提出的方案

![05_本地消息表方案](9.%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/05_%E6%9C%AC%E5%9C%B0%E6%B6%88%E6%81%AF%E8%A1%A8%E6%96%B9%E6%A1%88.png)

大量并发的时候，基于消息表，这样可能会有问题。



### 可靠消息最终一致性方案（最靠谱）



![06_可靠消息最终一致性方案](9.%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/06_%E5%8F%AF%E9%9D%A0%E6%B6%88%E6%81%AF%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E6%96%B9%E6%A1%88.png)

### 最大努力通知

![07_最大努力通知方案](9.%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/07_%E6%9C%80%E5%A4%A7%E5%8A%AA%E5%8A%9B%E9%80%9A%E7%9F%A5%E6%96%B9%E6%A1%88.png)



## 石杉的经验

我们的经验，我带几十人的team，最大的一个项目，起码几百个服务，复杂的分布式大型系统，里面其实也**没几个**分布式事务。

你其实用任何一个分布式事务的这么一个方案，都会导致你那块儿代码会复杂10倍。很多情况下，系统A调用系统B、系统C、系统D，我们可能根本就不做分布式事务。如果调用报错会打印异常日志。

每个月也就那么几个bug，很多bug是功能性的，体验性的，真的是涉及到数据层面的一些bug，一个月就几个，两三个？如果你为了确保系统自动保证数据100%不能错，上了几十个分布式事务，代码太复杂；性能太差，系统吞吐量、性能大幅度下跌。

99%的分布式接口调用，不要做分布式事务，直**接就是监控（发邮件、发短信）、记录日志（一旦出错，完整的日志）、事后快速的定位、排查和出解决方案、修复数据**。



















