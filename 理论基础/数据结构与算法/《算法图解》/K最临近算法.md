* K最临近算法创建分类系统
* 学习特征抽取
* 学习回归
* 学习K最临近算法的应用案例以及局限性

KNN算法很简单，但是非常有用。他可以用于对一样东西进行分类。

## 电影推荐系统

将所有用户都放在一个坐标系中，用户在图表中的位置取决于其喜好，喜好相似的用户距离较近。

距离指出了2组数字之间的相似程度。公式为：$\sqrt{(x1 - x2)^2 + (y1 - y2)^2}$

<img src="assets/K%E6%9C%80%E4%B8%B4%E8%BF%91%E7%AE%97%E6%B3%95/image-20230212130950978.png" alt="image-20230212130950978" style="zoom:50%;" />

在电影推荐系统中，用户的喜好有5个维度：喜剧、动作、生活、恐怖、爱情。

每个用户都在一个维度上，对其喜好程度进行打分。

![image-20230212131235299](assets/K%E6%9C%80%E4%B8%B4%E8%BF%91%E7%AE%97%E6%B3%95/image-20230212131235299.png)

从数学角度上来看，这是在五维空间中计算两点之间的距离，公式为：$\sqrt{(a1 - a2)^2 + (b1 - b2)^2 + (c1 - c2)^2 + (d1 - d2)^2 + (e1 - e2)^2}$

> 工作中常用余弦相似度去计算相似程度，而不是距离公式。



回归：预测Priyanka会对某部电影打多少分，先找出与其最相近的5个人，然后计算这5个人给电影打分的平局值，即可计算出回归值。

分类和回归：

* 分类就是编组
* 回归就是预测结果



挑选合适的特征，尤其重要。合适的特征是指：

* 与要推荐的电影紧密相关的特征；
* 不偏不倚的特征。











